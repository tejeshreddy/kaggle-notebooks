# [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)

## Table of Contents
- [Overview](#overview)
- [Notebooks](#notebooks)
- [Tools and Libraries Used](#tools-and-libraries-used)
- [Models and Eval Metrics](#models-and-eval-metrics)
- [Future Scope](#future-scope)

## Overview
This is an IPython Notebook for the Kaggle competition, Titanic Machine Learning From Disaster. This [Notebook](titanic-analysis.ipynb) aims at performing EDA(explanatory data analysis) on the dataset along with generating a [submission.csv](catboost_submission.csv) by running several classifier model.

## Notebooks
- [EDA and Model Building](titanic-analysis.ipynb)

## Tools and Libraries Used
- Sklearn
- Catboost

## Models and Eval Metrics
| Model | Accuracy Score |
| :-: | :-: |
| Decision Tree ||
| Gradient Boosting Trees ||
| CatBoost | 81.66% |
| Logistic Regression ||
| Naive Bayes ||
| Linear SVC ||
| Stochastic Gradient Decent ||

## Future Scope
- Hypertune catboost model to enhance accuracy
- Use keras to build NN
